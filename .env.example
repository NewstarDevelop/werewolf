# ==============================================================================
# Werewolf AI - Environment Configuration Template
# ==============================================================================
#
# Quick Start:
#   1. cp .env.example .env
#   2. Set JWT_SECRET_KEY (required)
#   3. Set OPENAI_API_KEY or LLM_USE_MOCK=true
#   4. docker compose up -d
#
# ==============================================================================


# ------------------------------------------------------------------------------
# 1. Core Configuration
# ------------------------------------------------------------------------------

# JWT Secret Key [required]
# Used for player authentication and WebSocket connections
# Generate: openssl rand -hex 32
JWT_SECRET_KEY=

# OpenAI API Key [recommended]
# Get yours at: https://platform.openai.com/api-keys
# If not set, use LLM_USE_MOCK=true for testing
OPENAI_API_KEY=

# OpenAI API Base URL [optional]
# For custom API endpoints (e.g., proxy services)
# OPENAI_BASE_URL=https://api.openai.com/v1


# ------------------------------------------------------------------------------
# 2. LLM Model Configuration
# ------------------------------------------------------------------------------

# Default LLM model
LLM_MODEL=gpt-4o-mini

# Maximum API call retries
LLM_MAX_RETRIES=2

# Mock mode (no real API calls, for testing)
# Set to true if no API key is configured
LLM_USE_MOCK=false


# ------------------------------------------------------------------------------
# 3. Application Configuration
# ------------------------------------------------------------------------------

# Debug mode
DEBUG=false

# Log level: DEBUG | INFO | WARNING | ERROR
LOG_LEVEL=INFO

# Data storage directory (for SQLite database, etc.)
DATA_DIR=data


# ------------------------------------------------------------------------------
# 4. Admin Features Configuration
# ------------------------------------------------------------------------------

# Environment variable management toggle
# When enabled, allows editing .env via admin panel
# Recommended: disable in production
# Note: This only affects env editing, not admin panel login
ENV_MANAGEMENT_ENABLED=false


# ------------------------------------------------------------------------------
# 5. Security Configuration
# ------------------------------------------------------------------------------

# Admin Password [recommended]
# Simple password authentication for admin panel
ADMIN_PASSWORD=

# Admin Key [backup]
# Generate: openssl rand -hex 16
ADMIN_KEY=

# Admin Key toggle
# Recommended: disable in production, use JWT admin token instead
ADMIN_KEY_ENABLED=false

# Debug mode (controls debug-messages API endpoint)
DEBUG_MODE=false

# Trusted proxies (for correct client IP detection)
# Format: comma-separated IPs or CIDRs
# Example: 127.0.0.1,10.0.0.0/8,172.16.0.0/12,192.168.0.0/16
# Empty = trust no proxy (use direct connection IP)
# TRUSTED_PROXIES=127.0.0.1

# CORS Configuration [docker deploy required]
# Format: comma-separated allowed origins
#
# WARNING: Using "*" disables Cookie authentication,
#          causing room creation and other features to fail!
#
# Docker deployment - set to your actual domain:
CORS_ORIGINS=https://your-domain.com
#
# Local development example:
# CORS_ORIGINS=http://localhost:5173,http://localhost:3000
#
# Multiple domains example:
# CORS_ORIGINS=https://your-domain.com,https://www.your-domain.com


# ------------------------------------------------------------------------------
# 6. JWT Authentication Configuration
# ------------------------------------------------------------------------------

# JWT signing algorithm
JWT_ALGORITHM=HS256

# JWT expiration time (minutes)
# Default: 7 days = 60 * 24 * 7 = 10080
JWT_EXPIRE_MINUTES=10080


# ------------------------------------------------------------------------------
# 7. OAuth SSO (linux.do)
# ------------------------------------------------------------------------------
# Create an app in linux.do developer console to get credentials

# OAuth app credentials
# LINUXDO_CLIENT_ID=your_client_id
# LINUXDO_CLIENT_SECRET=your_client_secret

# OAuth callback URL (must match console configuration)
# LINUXDO_REDIRECT_URI=https://your-domain.com/api/auth/callback/linuxdo

# OAuth endpoints (usually no need to change)
# LINUXDO_AUTHORIZE_URL=https://connect.linux.do/oauth2/authorize
# LINUXDO_TOKEN_URL=https://connect.linux.do/oauth2/token
# LINUXDO_USERINFO_URL=https://connect.linux.do/api/user
# LINUXDO_SCOPES=user


# ------------------------------------------------------------------------------
# 8. AI Game Analysis Configuration
# ------------------------------------------------------------------------------
# Separate from game AI, for post-game analysis

# Analysis-specific Provider [optional]
# Options: openai, deepseek, anthropic, moonshot, qwen, glm, doubao, minimax
# If not set, uses default OpenAI configuration
# ANALYSIS_PROVIDER=

# Analysis-specific model (recommend advanced models)
ANALYSIS_MODEL=gpt-4o

# Analysis mode
# comprehensive = detailed analysis
# quick = fast analysis
# custom = custom settings
ANALYSIS_MODE=comprehensive

# Analysis language
# auto = auto-detect | zh = Chinese | en = English
ANALYSIS_LANGUAGE=auto

# Analysis result caching
ANALYSIS_CACHE_ENABLED=true

# Analysis generation parameters
ANALYSIS_MAX_TOKENS=4000
ANALYSIS_TEMPERATURE=0.7


# ------------------------------------------------------------------------------
# 9. Multi-Provider Configuration
# ------------------------------------------------------------------------------
# Supported: OPENAI, ANTHROPIC, DEEPSEEK, MOONSHOT, QWEN, GLM, DOUBAO, MINIMAX
# Each supports: {PREFIX}_API_KEY, {PREFIX}_BASE_URL, {PREFIX}_MODEL,
#                {PREFIX}_MAX_RETRIES, {PREFIX}_TEMPERATURE, {PREFIX}_MAX_TOKENS

# --- DeepSeek ---
# DEEPSEEK_API_KEY=
# DEEPSEEK_BASE_URL=https://api.deepseek.com/v1
# DEEPSEEK_MODEL=deepseek-chat
# DEEPSEEK_MAX_RETRIES=2
# DEEPSEEK_TEMPERATURE=0.7
# DEEPSEEK_MAX_TOKENS=500

# --- Anthropic Claude ---
# ANTHROPIC_API_KEY=
# ANTHROPIC_BASE_URL=https://api.anthropic.com/v1
# ANTHROPIC_MODEL=claude-3-haiku-20240307
# ANTHROPIC_MAX_RETRIES=2
# ANTHROPIC_TEMPERATURE=0.7
# ANTHROPIC_MAX_TOKENS=500

# --- Moonshot ---
# MOONSHOT_API_KEY=
# MOONSHOT_BASE_URL=https://api.moonshot.cn/v1
# MOONSHOT_MODEL=moonshot-v1-8k
# MOONSHOT_MAX_RETRIES=2
# MOONSHOT_TEMPERATURE=0.7
# MOONSHOT_MAX_TOKENS=500

# --- Qwen (Tongyi Qianwen) ---
# QWEN_API_KEY=
# QWEN_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1
# QWEN_MODEL=qwen-turbo
# QWEN_MAX_RETRIES=2
# QWEN_TEMPERATURE=0.7
# QWEN_MAX_TOKENS=500

# --- GLM (Zhipu) ---
# GLM_API_KEY=
# GLM_BASE_URL=https://open.bigmodel.cn/api/paas/v4
# GLM_MODEL=glm-4-flash
# GLM_MAX_RETRIES=2
# GLM_TEMPERATURE=0.7
# GLM_MAX_TOKENS=500

# --- Doubao ---
# DOUBAO_API_KEY=
# DOUBAO_BASE_URL=https://ark.cn-beijing.volces.com/api/v3
# DOUBAO_MODEL=doubao-pro-4k
# DOUBAO_MAX_RETRIES=2
# DOUBAO_TEMPERATURE=0.7
# DOUBAO_MAX_TOKENS=500

# --- MiniMax ---
# MINIMAX_API_KEY=
# MINIMAX_BASE_URL=https://api.minimax.chat/v1
# MINIMAX_MODEL=abab6.5s-chat
# MINIMAX_MAX_RETRIES=2
# MINIMAX_TEMPERATURE=0.7
# MINIMAX_MAX_TOKENS=500

# --- Custom Provider (1-9) ---
# AI_PROVIDER_1_NAME=custom
# AI_PROVIDER_1_API_KEY=
# AI_PROVIDER_1_BASE_URL=https://your-api.com/v1
# AI_PROVIDER_1_MODEL=your-model
# AI_PROVIDER_1_MAX_RETRIES=2
# AI_PROVIDER_1_TEMPERATURE=0.7
# AI_PROVIDER_1_MAX_TOKENS=500


# ------------------------------------------------------------------------------
# 10. Per-Player AI Configuration
# ------------------------------------------------------------------------------
# Configure different AI for different seats (2-9) for diverse gameplay

# --- Method 1: Dedicated Configuration ---
# Configure independent LLM for specific seats (creates player_{seat_id} provider)
# AI_PLAYER_2_API_KEY=
# AI_PLAYER_2_BASE_URL=https://api.openai.com/v1
# AI_PLAYER_2_MODEL=gpt-4o-mini
# AI_PLAYER_2_TEMPERATURE=0.7
# AI_PLAYER_2_MAX_TOKENS=500
# AI_PLAYER_2_MAX_RETRIES=2

# --- Method 2: Map to Existing Provider ---
# Map seats to providers configured above (highest priority)
# AI_PLAYER_2_PROVIDER=deepseek
# AI_PLAYER_3_PROVIDER=anthropic
# AI_PLAYER_4_PROVIDER=openai

# --- Method 3: Batch JSON Mapping ---
# Configure multiple seat-provider mappings at once
# AI_PLAYER_MAPPING={"2":"deepseek","3":"anthropic","4":"openai","5":"moonshot"}


# ------------------------------------------------------------------------------
# 11. Rate Limiting Configuration
# ------------------------------------------------------------------------------
# Control AI request rate and concurrency

# Default provider rate limits
DEFAULT_REQUESTS_PER_MINUTE=60
DEFAULT_MAX_CONCURRENCY=5
DEFAULT_BURST=3

# Per-game LLM request control
LLM_MAX_WAIT_SECONDS=8
LLM_PER_GAME_MIN_INTERVAL=0.5
LLM_PER_GAME_MAX_CONCURRENCY=2


# ------------------------------------------------------------------------------
# 12. Redis Configuration (Notification System)
# ------------------------------------------------------------------------------
# For cross-instance message broadcasting

# Redis connection URL [optional]
# Format: redis://[:password]@host:port/db
# Example: redis://localhost:6379/0
#
# Development: System falls back to single-instance mode without Redis
# Production: Recommended for multi-instance deployment
# REDIS_URL=


# ------------------------------------------------------------------------------
# 13. Frontend Configuration (Vite)
# ------------------------------------------------------------------------------
# For Docker deployment, frontend uses nginx reverse proxy, usually no config needed
# For local development direct backend connection

# Backend API URL
# VITE_API_URL=http://localhost:8082
# VITE_API_BASE_URL=http://localhost:8082

# --- Sentry Error Monitoring ---
# VITE_SENTRY_DSN=https://xxx@sentry.io/xxx
# VITE_SENTRY_ENV=production

# Performance monitoring sample rate (0.0 - 1.0)
# VITE_SENTRY_TRACES_SAMPLE_RATE=0.1

# Session Replay configuration
# VITE_SENTRY_ENABLE_REPLAY=false
# VITE_SENTRY_REPLAYS_SESSION_SAMPLE_RATE=0.1
# VITE_SENTRY_REPLAYS_ON_ERROR_SAMPLE_RATE=1.0


# ------------------------------------------------------------------------------
# 14. Database Configuration
# ------------------------------------------------------------------------------

# Run database migrations on startup
# Set to false to skip auto-migration (for manual runs)
RUN_DB_MIGRATIONS=true


# ==============================================================================
# Configuration Examples
# ==============================================================================
#
# --- Minimal Configuration (OpenAI only) ---
# JWT_SECRET_KEY=your-random-secret-key-at-least-32-characters
# OPENAI_API_KEY=sk-your-key-here
#
# --- Mock Mode (no API key needed) ---
# JWT_SECRET_KEY=your-random-secret-key-at-least-32-characters
# LLM_USE_MOCK=true
#
# --- Multi-Provider Battle ---
# JWT_SECRET_KEY=xxx
# OPENAI_API_KEY=sk-xxx
# DEEPSEEK_API_KEY=sk-xxx
# ANTHROPIC_API_KEY=sk-ant-xxx
# AI_PLAYER_MAPPING={"2":"openai","3":"deepseek","4":"anthropic"}
#
# ==============================================================================
